{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4be37a-9256-4724-bd9c-a3990631c3c9",
   "metadata": {},
   "source": [
    "Q1 Age Detection Dataset\t50 MB, Age recognition, 3 classes: old, middle, young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e050ef76-feaf-4673-8d69-e89e58f17300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T10:02:24.469040Z",
     "start_time": "2024-12-11T10:02:23.953396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/faustyn/.cache/kagglehub/datasets/arashnic/faces-age-detection-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"arashnic/faces-age-detection-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "#načítame dataset s kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4ae1f8-c27a-4f50-a392-f3044fe88d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result examples:\n",
      "          ID   Class\n",
      "0    377.jpg  MIDDLE\n",
      "1  17814.jpg   YOUNG\n",
      "2  21283.jpg  MIDDLE\n",
      "3  16496.jpg   YOUNG\n",
      "4   4487.jpg  MIDDLE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = \"/Users/faustyn/.cache/kagglehub/datasets/arashnic/faces-age-detection-dataset/versions/2/faces\"\n",
    "#do cesty je potrebné pridať svojho usera\n",
    "csv_file = os.path.join(path, \"train.csv\")\n",
    "csv = pd.read_csv(csv_file)\n",
    "print(\"Result examples:\")\n",
    "print(csv.head())\n",
    "#zapís do jedného súboru\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207f1cd-f9bd-43b1-890b-19021bb04186",
   "metadata": {},
   "source": [
    "Podľa formátu súboru vidíme, že máme dva stĺpce, kde jeden označuje obrázok a druhý označuje typ veku osoby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79b77f69-6db6-4991-a8c6-d590c081caec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv[\"Class\"].hist(bins=20, edgecolor='black', figsize=(8, 6))\n",
    "plt.xlabel(\"Types\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "#úkažka koľko máme s každého týpu v nášom datasete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc3ed37-949e-47cf-a784-434587b0ad20",
   "metadata": {},
   "source": [
    "Graf zobrazuje všetky typy vekových skupín v našom súbore údajov a ich počet a ako ich vidíme, najväčší počet pripadá na populáciu stredného veku, \n",
    "mladých ľudí je takmer o polovicu menej a starých ľudí je 1/4 populácie stredného veku\n",
    "\n",
    "Na základe tohto počtu môžeme mať problém, že údaje na trénovanie nie sú presne a rovnomerne rozdelené, ale to ešte musíme dokázať a preukázať. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "094ef01d-1f83-4bdf-bef1-939a60364caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_folder = \"/Users/faustyn/.cache/kagglehub/datasets/arashnic/faces-age-detection-dataset/versions/2/faces/Train\"\n",
    "#do cesty je potrebné pridať svojho usera\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "\n",
    "# scan all imagess\n",
    "for img_file in os.listdir(image_folder):\n",
    "    if img_file.endswith((\".jpg\")):  # Проверяем формат\n",
    "        img_path = os.path.join(image_folder, img_file)\n",
    "        with Image.open(img_path) as img:\n",
    "            widths.append(img.width)\n",
    "            heights.append(img.height)\n",
    "    else:\n",
    "        print(\"Incorrect format of image\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(widths, bins=20, edgecolor='black')\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(heights, bins=20, edgecolor='black')\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#kontrola formatu obrazkov v datasete,na trening mali by byť rovnakého formatu,ale zistilo sa že to tak nie je,nížšie máme graf s šírkámi a výškami\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f29905-bccc-4178-8bfd-2475dc699bc4",
   "metadata": {},
   "source": [
    "Weight: Väčšina obrázkov má šírku od 50 do 200 pixelov\n",
    "Height: Podobne má väčšina obrázkov výšku medzi 50 a 200 pixelmi\n",
    "Pri výbere optimálnej veľkosti na kompresiu budeme brať do úvahy priemernú hodnotu aj potrebu znížiť stratu kvality počas spracovania\n",
    "\n",
    "Optimálna veľkosť pre kompresiu:\n",
    "128x128 pixelov\n",
    "\n",
    "Keďže spadáme do rozsahu väčšiny obrázkov (50-200)\n",
    "Vhodné pre modely hlbokého učenia (veľkosti sú násobkom 2).\n",
    "Zachováva rovnováhu medzi veľkosťou obrázka a rýchlosťou spracovania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5653dd3e-8377-4a8e-b55b-302250f45ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls detected:\n",
      "ID       0\n",
      "Class    0\n",
      "dtype: int64\n",
      "\n",
      "Duplicates detected: 0\n",
      "ID: 19906 unique values\n",
      "Class: 3 unique values\n"
     ]
    }
   ],
   "source": [
    "print(\"Nulls detected:\")\n",
    "print(csv.isnull().sum())\n",
    "print()\n",
    "print(\"Duplicates detected:\", csv.duplicated().sum())\n",
    "\n",
    "for column in csv.columns:\n",
    "    print(f\"{column}: {csv[column].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d63e5-144f-4933-940a-43b3f297bddc",
   "metadata": {},
   "source": [
    "Duplikáty ne boli najdene\n",
    "\n",
    "Počet jedinečných ID 19906 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a569e65-840c-45a2-a6d5-5c160725d380",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e353d16-2320-41e3-9c21-82d167e96b8f",
   "metadata": {},
   "source": [
    "Konvertujeme všetky obrázky do formátu RGB a tiež do veľkosti 128x128 a retejtneme ich a na to všetko použijeme library albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37f6fb6e-453b-40a2-bcec-0c91392662b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faustyn/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/albumentations/check_version.py:51: UserWarning: Error fetching version info <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\n",
      "  data = fetch_version_info()\n",
      "100%|██████████| 19906/19906 [00:13<00:00, 1502.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# output priečínok\n",
    "output_folder = os.path.join(path, \"processed_images\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ten pipeline je potrebný na to aby rôznymi spôsobmi meniť,pozitívne to ovplyvňuje výsledky,lebo nn učí sa na rôznych datách \n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.Resize(128, 128),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for img_file in tqdm(os.listdir(image_folder)):\n",
    "    if img_file.endswith(\".jpg\"):\n",
    "        img_path = os.path.join(image_folder, img_file)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        # kontrolujeme či sa náchadzá súbor v annotáciach\n",
    "        if img_file not in csv[\"ID\"].values:\n",
    "            print(f\"Image {img_file} is not in annotation, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # konvergujeme všetko do RGB \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # aplikujeme transformácie\n",
    "        augmented = transform(image=image)[\"image\"]\n",
    "\n",
    "        # konvertujeme tenzor do NumPy pre saving\n",
    "        augmented_image = augmented.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "        # úchovame procesované obrazky\n",
    "        output_path = os.path.join(output_folder, img_file)\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab2216c-af07-42df-99aa-e26f32ef4437",
   "metadata": {},
   "source": [
    "Previdime triedy („MIDDLE“, „YOUNG“, „OLD“) na číselné hodnoty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a87748b-fa49-408a-b2c3-5c98fa169091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Class: ['MIDDLE' 'YOUNG' 'OLD']\n",
      "Coded values in age_group_encoded: [0 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "csv[\"age_group_encoded\"] = encoder.fit_transform(csv[\"Class\"])\n",
    "\n",
    "print(\"Unique values in Class:\", csv[\"Class\"].unique())\n",
    "print(\"Coded values in age_group_encoded:\", csv[\"age_group_encoded\"].unique())\n",
    "\n",
    "csv.to_csv(\"processed_train.csv\", index=False)\n",
    "#encode "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360365a-fb1f-479b-a11d-2cf379368ee8",
   "metadata": {},
   "source": [
    "rozdeľme naše data na testováciu,trénováciu a validation množíny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d68d00b3-68e0-4060-a4f4-a927dff5dd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 11943\n",
      "Valid: 3981\n",
      "Test: 3982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(csv, test_size=0.2, random_state=1)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=1)  # na validáciu stáči 20 percent\n",
    "\n",
    "train_data.to_csv(\"processed_train.csv\", index=False)\n",
    "val_data.to_csv(\"processed_val.csv\", index=False)\n",
    "test_data.to_csv(\"processed_test.csv\", index=False)\n",
    "\n",
    "print(f\"Train : {len(train_data)}\")\n",
    "print(f\"Valid: {len(val_data)}\")\n",
    "print(f\"Test: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341e792-1bce-4edd-a729-27c1c466f8a9",
   "metadata": {},
   "source": [
    "Mame za vyber Hlboké učenie (Deep Learning)\n",
    "\n",
    "Keďže dataset obsahuje ID obrázkov, DL je pravdepodobne najlepšou voľbou, pretože dokáže automaticky extrahovať črty z obrázkov a riešiť zložité problémy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda445ce-4332-4a95-8083-0ba5e8c54997",
   "metadata": {},
   "source": [
    "**Modeling and evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a02b2-826a-4508-98cc-48f41593b9c5",
   "metadata": {},
   "source": [
    "Po spracovaní obrázkov a ich rozdelení do tréningovej, validačnej a testovacej sady vytvorme načítavač údajov, ktorý bude čítať obrázky zo zložky output_folder a priraďovať ich k štítkom zo súboru processed_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad908cc3-cdd6-4c52-8201-947bfcb2e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class AgeDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.data.iloc[idx, 0])  # Assuming 'Image ID' is in column 0\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label = self.data.iloc[idx, -1]  # Assuming 'age_group_encoded' is the last column\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd9687e-7f87-455b-b77d-5788cfbff5b7",
   "metadata": {},
   "source": [
    "DataLoader na načítanie údajov po batčach do modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "708aadd9-8b26-4e8f-9110-7be621a385fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = AgeDataset(csv_file=\"processed_train.csv\", image_folder=output_folder, transform=data_transforms)\n",
    "val_dataset = AgeDataset(csv_file=\"processed_val.csv\", image_folder=output_folder, transform=data_transforms)\n",
    "test_dataset = AgeDataset(csv_file=\"processed_test.csv\", image_folder=output_folder, transform=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e8c3d-e927-49f7-bb97-4e175f80d423",
   "metadata": {},
   "source": [
    "Naš dataset obsahuje veľké množstvo obrázkov a preto použime Transfer Learning s CNN (ako ResNet50 / EfficientNet) a vyskušajme a ine modely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35f50080-7145-4a95-a7f9-61953a20a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout layer\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x.view(-1, 64 * 32 * 32))  # Flatten with Dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Dropout before final layer\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(num_classes=3)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct.double() / len(loader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct.double() / len(loader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbd4e08d-531e-463f-b641-8dad2958309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train loss: 0.9437, Train acc: 0.5716\n",
      "Val loss: 0.8459, Val acc: 0.6149\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion, device)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f}\")\n",
    "    print(f\"Val loss: {val_loss:.4f}, Val acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e51575-f174-45d7-9406-097a83075cbb",
   "metadata": {},
   "source": [
    "РЕЗУЛЬТАТЫ МОДЕЛИ В ЛОСЕ проверка на андер и овер фитинг "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90e49b77-6ab9-42f3-a6d5-241b606885a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/646fhd_x0vz_f_b50b5kmsgm0000gn/T/ipykernel_82230/3838296923.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(output_path)\n"
     ]
    }
   ],
   "source": [
    "#Model: Transfer Learning (ResNet50)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "import ssl\n",
    "import urllib.request\n",
    "import certifi\n",
    "\n",
    "# Create SSL context with updated certificates\n",
    "ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "url = \"https://download.pytorch.org/models/resnet50-0676ba61.pth\"\n",
    "output_path = \"resnet50-0676ba61.pth\"  # Replace with your desired save path\n",
    "\n",
    "# Use urlopen with SSL context\n",
    "with urllib.request.urlopen(url, context=ssl_context) as response, open(output_path, 'wb') as out_file:\n",
    "    out_file.write(response.read())\n",
    "\n",
    "print(\"File downloaded successfully!\")\n",
    "\n",
    "\n",
    "class ResNet50TransferLearning(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet50TransferLearning, self).__init__()\n",
    "\n",
    "        self.resnet50 = resnet50(weights=None)  # Initialize without weights\n",
    "\n",
    "        \n",
    "        state_dict = torch.load(output_path)\n",
    "        self.resnet50.load_state_dict(state_dict)\n",
    "        \n",
    "        for param in self.resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        in_features = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),  # projection layer\n",
    "            nn.ReLU(),                            # activation\n",
    "            nn.Dropout(p=dropout_rate),           # Dropout\n",
    "            nn.Linear(in_features, num_classes)   # output layer\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "\n",
    "# Model Parameters\n",
    "num_classes = 3\n",
    "\n",
    "# Initialize Model\n",
    "model2 = ResNet50TransferLearning(num_classes=num_classes)\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model2 = model2.to(device)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.resnet50.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Training Function\n",
    "def train(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct.double() / len(loader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Validation Function\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = correct.double() / len(loader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42091a15-e5f6-4a0f-86eb-4e2f5082a78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train loss: 0.8048, Train acc: 0.6355\n",
      "Val loss: 0.7878, Val acc: 0.6441\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion, device)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[64], line 68\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     65\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     67\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 68\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     70\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[41], line 16\u001b[0m, in \u001b[0;36mSimpleCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m))  \u001b[38;5;66;03m# Flatten with Dropout\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[0;32m~/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/STU_2324/IAU/IAU_Project/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f}\")\n",
    "    print(f\"Val loss: {val_loss:.4f}, Val acc: {val_acc:.4f}\")\n",
    "\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee947ed4-8edf-4e88-be93-e3f3219aced0",
   "metadata": {},
   "source": [
    "РЕЗУЛЬТАТЫ МОДЕЛИ В ЛОСЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3c04676-78a9-4772-a789-f22921391f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model: Random Forest\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import numpy as np\n",
    "\n",
    "# Класс для использования Random Forest в стиле PyTorch\n",
    "class RandomForestModel:\n",
    "    def __init__(self, num_classes, n_estimators=100):\n",
    "        self.num_classes = num_classes\n",
    "        self.model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# Предобработка данных для Random Forest\n",
    "# Пример: преобразование тензоров PyTorch в numpy\n",
    "\n",
    "def preprocess_loader(loader, device):\n",
    "    X, y = [], []\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device).view(images.size(0), -1).cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        X.append(images)\n",
    "        y.append(labels)\n",
    "    return np.vstack(X), np.hstack(y)\n",
    "\n",
    "# Инициализация модели Random Forest\n",
    "num_classes = 3\n",
    "rf_model = RandomForestModel(num_classes=num_classes)\n",
    "\n",
    "# Устройство\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Функция обучения\n",
    "def train_rf(model, loader, device):\n",
    "    X_train, y_train = preprocess_loader(loader, device)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Функция валидации\n",
    "def validate_rf(model, loader, device):\n",
    "    X_val, y_val = preprocess_loader(loader, device)\n",
    "    predictions = model.predict(X_val)\n",
    "    probabilities = model.predict_proba(X_val)\n",
    "    loss = log_loss(y_val, probabilities)\n",
    "    acc = accuracy_score(y_val, predictions)\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9f22b-f3ea-48a7-914c-0df75d070bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1  # Random Forest обучается за один \"эпоху\"\n",
    "train_rf(rf_model, train_loader, device)\n",
    "\n",
    "# Валидация модели\n",
    "val_loss, val_acc = validate_rf(rf_model, val_loader, device)\n",
    "print(f\"Validation loss: {val_loss:.4f}, Validation acc: {val_acc:.4f}\")\n",
    "\n",
    "# Тестирование модели\n",
    "test_loss, test_acc = validate_rf(rf_model, test_loader, device)\n",
    "print(f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f803514-382d-4575-88d1-859a3b6774ee",
   "metadata": {},
   "source": [
    "РЕЗУЛЬТАТЫ МОДЕЛИ В ЛОСЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49aee5a-94de-4fc4-b7b2-edab5d256dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model: SVM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import numpy as np\n",
    "\n",
    "# Класс для использования SVM в стиле PyTorch\n",
    "class SVMModel:\n",
    "    def __init__(self, num_classes, kernel='linear', C=1.0):\n",
    "        self.num_classes = num_classes\n",
    "        self.model = SVC(kernel=kernel, C=C, probability=True)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "# Предобработка данных для SVM\n",
    "# Пример: преобразование тензоров PyTorch в numpy\n",
    "\n",
    "def preprocess_loader(loader, device):\n",
    "    X, y = [], []\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device).view(images.size(0), -1).cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        X.append(images)\n",
    "        y.append(labels)\n",
    "    return np.vstack(X), np.hstack(y)\n",
    "\n",
    "# Инициализация модели SVM\n",
    "num_classes = 3\n",
    "svm_model = SVMModel(num_classes=num_classes, kernel='rbf', C=1.0)\n",
    "\n",
    "# Устройство\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Функция обучения\n",
    "def train_svm(model, loader, device):\n",
    "    X_train, y_train = preprocess_loader(loader, device)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Функция валидации\n",
    "def validate_svm(model, loader, device):\n",
    "    X_val, y_val = preprocess_loader(loader, device)\n",
    "    predictions = model.predict(X_val)\n",
    "    probabilities = model.predict_proba(X_val)\n",
    "    loss = log_loss(y_val, probabilities)\n",
    "    acc = accuracy_score(y_val, predictions)\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45049eff-1e51-4376-928e-0228997b3bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение модели\n",
    "num_epochs = 1  # SVM обучается за один \"эпоху\"\n",
    "train_svm(svm_model, train_loader, device)\n",
    "\n",
    "# Валидация модели\n",
    "val_loss, val_acc = validate_svm(svm_model, val_loader, device)\n",
    "print(f\"Validation loss: {val_loss:.4f}, Validation acc: {val_acc:.4f}\")\n",
    "\n",
    "# Тестирование модели\n",
    "test_loss, test_acc = validate_svm(svm_model, test_loader, device)\n",
    "print(f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007340bb-aac5-4491-b086-6cb0386df010",
   "metadata": {},
   "source": [
    "РЕЗУЛЬТАТЫ МОДЕЛИ В ЛОСЕ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d25b752-f73e-4a71-8f0d-d0dbbf2d7809",
   "metadata": {},
   "source": [
    "**Porovnanie výkonnosti**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa2632-bb3f-4c67-b3ac-41c13e03a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#посчитать акураси и нет ли овер или андер фитинга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd1fa65-196d-4e10-8c92-713bd30c6f53",
   "metadata": {},
   "source": [
    "СРАВНЕНИЕ МОДЕЛЕЙ В АКУРАСИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c57f2f-4058-4bdb-a8f2-c06869fdc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "Итоги и выбор лучшой модели и ее резултаты при трейн тесте акуранси и валидации"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
